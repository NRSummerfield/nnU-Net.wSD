{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - Inherent\n",
    "import os, glob, datetime, math as m, logging, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports - Base Modules\n",
    "import torch, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from monai.metrics.meandice import DiceMetric\n",
    "from monai.metrics import HausdorffDistanceMetric, SurfaceDistanceMetric\n",
    "from monai.data.dataloader import DataLoader\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "\n",
    "# Imports - Robert's Torch Manager\n",
    "from torchmanager_monai import metrics, Manager as UntManager\n",
    "from torchmanager_monai import Manager as UntManager\n",
    "\n",
    "# Imports - Our Code\n",
    "from stuff import data\n",
    "\n",
    "# from SpatialHDMetric import SpatialHausdorffDistanceMetric\n",
    "# from metrics.selective_input import simple_dice3D, grouped_metric\n",
    "\n",
    "\n",
    "from monai.networks.nets.unet import UNet\n",
    "base_model = UNet\n",
    "class model_dict(base_model):\n",
    "    def forward(self, x):\n",
    "        y = super().forward(x)\n",
    "        return {'out': y} if self.training else y\n",
    "\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from monai.inferers.utils import sliding_window_inference\n",
    "save_dir = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained Manager/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = \"experiments/Deeper_nnUNETwSD_Oct4_1.exp/best_dice.model\"\n",
    "\n",
    "# Best nnUNETwSD-Sim\n",
    "ckpt_path = 'experiments/Deep_nnUNetwSD_Best_NoSims.exp/best_dice.model'\n",
    "\n",
    "\n",
    "# Best nnUNETwSD-Sim+FX\n",
    "# ckpt_path = 'experiments/Deeper_nnUNETwSD_Oct3_1.exp/best_dice.model'\n",
    "\n",
    "# Best UNET\n",
    "# ckpt_path = \"experiments/UNET_onSortedInterpolatedData_Aug15.exp/best_dice.model\"\n",
    "\n",
    "# Loading the Manager\n",
    "manager = UntManager.from_checkpoint(ckpt_path, map_location=torch.device('cpu'))\n",
    "print(f'Running {ckpt_path}\\nSaved Epoch: {manager.current_epoch}')\n",
    "\n",
    "# # initialize the dice metric\n",
    "# dice_fn = metrics.CumulativeIterationMetric(DiceMetric(include_background=False, reduction=\"none\", get_not_nans=False))\n",
    "# metric_fns: dict[str, metrics.Metric] = {\"val_dice\": dice_fn}\n",
    "# manager.metric_fns = metric_fns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.645 0.59 0.64 0.64 0.627 0.621\n",
    "\n",
    "print(manager.notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_fn = metrics.CumulativeIterationMetric(DiceMetric(include_background=False, reduction=\"none\", get_not_nans=False), target=\"out\")\n",
    "# shd_fn = metrics.CumulativeIterationMetric(SpatialHausdorffDistanceMetric(include_background=False, reduction=\"none\", distance_metric='euclidean', percentile=95, sampling=(1.5,1.5,1.5)), target=\"out\")\n",
    "\n",
    "# dice_fn = metrics.CumulativeIterationMetric(DiceMetric(include_background=False, reduction=\"none\", get_not_nans=False))\n",
    "# shd_fn = metrics.CumulativeIterationMetric(SpatialHausdorffDistanceMetric(include_background=False, reduction=\"none\", distance_metric='euclidean', percentile=95, sampling=(1.5,1.5,3)))\n",
    "\n",
    "hd_fn = metrics.CumulativeIterationMetric(HausdorffDistanceMetric(include_background=False, reduction=\"none\", distance_metric='euclidean', percentile=95), target=\"out\")\n",
    "msd_fn = metrics.CumulativeIterationMetric(SurfaceDistanceMetric(include_background=False, reduction=\"none\", distance_metric='euclidean'), target=\"out\")\n",
    "\n",
    "# WH_dice = grouped_metric(simple_dice3D, indicies=[i for i in range(1, 13)], target='out')\n",
    "# GC_dice = grouped_metric(simple_dice3D, indicies=[1, 2, 3, 4], target='out')\n",
    "# GV_dice = grouped_metric(simple_dice3D, indicies=[5, 6, 7, 8, 9], target='out')\n",
    "# CA_dice = grouped_metric(simple_dice3D, indicies=[10, 11, 12], target='out')\n",
    "\n",
    "# WH = sel_DSC(indicies=[i for i in range(1, 13)])\n",
    "# GC = sel_DSC(indicies=[1, 2, 3, 4])\n",
    "# GV = sel_DSC(indicies=[5, 6, 7, 8, 9])\n",
    "# CA = sel_DSC(indicies=[10, 11, 12])\n",
    "\n",
    "metric_fns = {\n",
    "    'val_dice': dice_fn,\n",
    "    # 'val_shd': shd_fn,\n",
    "    'val_hd': hd_fn,\n",
    "    'val_msd': msd_fn\n",
    "    # 'val_WH_dice': WH_dice,\n",
    "    # 'val_GC_dice': GC_dice,\n",
    "    # 'val_GV_dice': GV_dice,\n",
    "    # 'val_CA_dice': CA_dice,\n",
    "}\n",
    "manager.metric_fns = metric_fns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the data to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_json = '/mnt/data/Summerfield/Data/ViewRay.data/ViewRay.Resampled_1mm/cohort.json'\n",
    "# src = '/mnt/data/Summerfield/Data/ViewRay.data/ViewRay.Resampled_1mm'\n",
    "# num_workers = 10\n",
    "# dataset_configuration = {\n",
    "#     'src': src,\n",
    "#     'data_json': data_json,\n",
    "#     'fold': 1,\n",
    "#     'roi_size': (200, 200, 200),\n",
    "#     'img_size': (144, 144, 144),\n",
    "#     'cached': True,\n",
    "#     'cache_num': (10, 10),\n",
    "#     'num_samples': 4,\n",
    "#     'num_workers': num_workers,\n",
    "#     'sim_only': True\n",
    "#     }\n",
    "\n",
    "# src = \"/mnt/data/Summerfield/Data/CasePrediction/to_model\"\n",
    "# data_json = \"/mnt/data/Summerfield/Data/CasePrediction/to_model/cohort.json\"\n",
    "src = '/mnt/data/Summerfield/Data/ViewRay.data/1.5mm_volumes.data'\n",
    "data_json=\"/mnt/data/Summerfield/Data/ViewRay.data/1.5mm_volumes.data/cohort.json\"\n",
    "num_workers = 10\n",
    "dataset_configuration = {\n",
    "    'src': src,\n",
    "    'data_json': data_json,\n",
    "    'fold': 1,\n",
    "    'roi_size': (128, 128, 128),\n",
    "    'img_size': (96, 96, 96),\n",
    "    'cached': True,\n",
    "    'cache_num': (10, 10),\n",
    "    'num_samples': 4,\n",
    "    'num_workers': num_workers,\n",
    "    'sim_only': True,\n",
    "    }\n",
    "\n",
    "# # UW external TEST\n",
    "# src = \"/mnt/data/Summerfield/Data/UWVR_Cardiac_MRsimOnly-Processed/for_model\"\n",
    "# data_json = \"/mnt/data/Summerfield/Data/UWVR_Cardiac_MRsimOnly-Processed/for_model/cohort.json\"\n",
    "# num_workers = 10\n",
    "# dataset_configuration = {\n",
    "#     'src': src,\n",
    "#     'data_json': data_json,\n",
    "#     'fold': 1,\n",
    "#     'roi_size': (128, 128, 128),\n",
    "#     'img_size': (96, 96, 96),\n",
    "#     'cached': True,\n",
    "#     'cache_num': (10, 10),\n",
    "#     'num_samples': 4,\n",
    "#     'num_workers': num_workers,\n",
    "#     'sim_only': True,\n",
    "#     }\n",
    "\n",
    "_, test_ds, paths = data.load_ViewRay(\n",
    "        testing_or_training='testing',  \n",
    "        logger=None,\n",
    "        return_testing_paths=True,\n",
    "        **dataset_configuration\n",
    ")\n",
    "testing_dataset = DataLoader(test_ds, batch_size=1, collate_fn=pad_list_data_collate, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model and recording results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the prediction masks\n",
    "# predictions = manager.predict(testing_dataset, device=device, show_verbose=True)\n",
    "# Getting the metrics\n",
    "manager.test(testing_dataset, device=device, show_verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, imgs = [], []\n",
    "\n",
    "for pred, img in zip(predictions, testing_dataset):\n",
    "    pred = pred.detach().cpu()\n",
    "    img = img['image'].detach().cpu()[:, 0]\n",
    "\n",
    "    one_hot_pred = torch.argmax(pred, dim=1)\n",
    "    print(one_hot_pred.shape, img.shape)\n",
    "\n",
    "    imgs.append(img)\n",
    "    preds.append(one_hot_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "img = imgs[n][0]\n",
    "WL = 0.4\n",
    "_max = img.max() * WL\n",
    "img = np.where(img > _max, _max, img)\n",
    "\n",
    "pred = preds[n][0]\n",
    "\n",
    "mask = np.ma.masked_where(pred == 0, pred)\n",
    "for i in range(128):\n",
    "    fig, axs = plt.subplots(ncols=2, dpi=200)\n",
    "    \n",
    "    ax: plt.Axes = axs[0]\n",
    "    ax.imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "    ax.set_title(f'slice {i}')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax: plt.Axes = axs[1]\n",
    "    ax.imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "    ax.imshow(mask[..., i], cmap='Reds', vmin=mask.min(), vmax=mask.max())\n",
    "    ax.set_title(f'Prediction')\n",
    "    ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img = np.stack(imgs, axis=0)[0]\n",
    "np_preds = np.stack(preds, axis=0)[0]\n",
    "# print(np_preds.shape)\n",
    "\n",
    "np.save('to_Carri-IMG.npy', arr=np_img, allow_pickle=True)\n",
    "np.save('to_Carri-PRED.npy', arr=np_preds, allow_pickle=True)\n",
    "\n",
    "# np.save('UWVR_Cardiac_FULL_nnUNETwSD_IMGS.npy', arr=np_img, allow_pickle=True)\n",
    "# np.save('UWVR_Cardiac_FULL_nnUNETwSD_PREDS.npy', arr=np_preds, allow_pickle=True)\n",
    "\n",
    "# np.save('UWVR_Cardiac_nnUNETwSD_Oct3_IMGS.npy', arr=np_img, allow_pickle=True)\n",
    "# np.save('UWVR_Cardiac_nnUNETwSD_Oct3_PREDS.npy', arr=np_preds, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_img.shape, np_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = manager.metric_fns['val_dice'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "# hd = manager.metric_fns['val_shd'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "hd = manager.metric_fns['val_hd'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "mda = manager.metric_fns['val_msd'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "\n",
    "\n",
    "print(dice.shape, type(dice))\n",
    "\n",
    "print(hd.shape, mda.shape, dice.shape)\n",
    "\n",
    "model_str = 'UNETR_2'\n",
    "np.save(f'ViewRay_Predictions/{model_str}_dice_metrics.npy', dice, allow_pickle=True)\n",
    "np.save(f'ViewRay_Predictions/{model_str}_HD_metrics.npy', hd, allow_pickle=True)\n",
    "np.save(f'ViewRay_Predictions/{model_str}_MDA_metrics.npy', mda, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of the testing images / labels\n",
    "imgs, labs = [], []\n",
    "for _set in testing_dataset:\n",
    "    img, lab = _set['image'][0, 0], _set['label'][0, 0]\n",
    "    imgs.append(img)\n",
    "    labs.append(lab)\n",
    "    \n",
    "preds = [pred[0] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.stack(preds, dim=0).cpu().numpy()\n",
    "imgs = torch.stack(imgs, dim=0).cpu().numpy()\n",
    "labs = torch.stack(labs, dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)\n",
    "print(imgs.shape)\n",
    "print(labs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 'nnUNET_WITH_SD'\n",
    "np.save(f'{n}_imgs', imgs, allow_pickle=True)\n",
    "np.save(f'{n}_labs', labs, allow_pickle=True)\n",
    "np.save(f'{n}_preds', preds, allow_pickle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics - DSC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout = print\n",
    "# cout = results_logger.info\n",
    "\n",
    "structures = ['RA','LA','RV','LV','AA','SVC','IVC','PA','PV','LMCA','LADA','RCA']\n",
    "cout(f'DSC for ViewRay patients (n={len(testing_dataset)})')\n",
    "\n",
    "dice = manager.metric_fns['val_dice'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "# dice = manager.metric_fns['val_dice'].results.type(torch.float).squeeze(1).cpu()[:, 1:].numpy()\n",
    "sub_std = np.std(dice, axis=0)\n",
    "\n",
    "p_dice = np.nanmean(dice, axis=1)\n",
    "# print(p_dice)\n",
    "cout(f'Total average DSC without background = {dice.mean():0.4} ± {p_dice.std():0.4f}')\n",
    "if save_dir: np.save(os.path.join(save_dir, 'DSC.metrics.npy'), dice)\n",
    "\n",
    "subs = np.nanmean(dice, axis=0)\n",
    "no_WH = subs[1:].mean()\n",
    "cout('Breakdown by substructure: (mean ± std)')\n",
    "[cout(f'\\tSub {structures[i]}: \\t{subs[i]:0.4f} ± {sub_std[i]:0.4f}') for i in range(len(subs))]\n",
    "\n",
    "print()\n",
    "\n",
    "# print(dice.shape)\n",
    "avg_GCs = np.nanmean(dice[:, :4], axis=1)\n",
    "avg_GVs = np.nanmean(dice[:, 4:9], axis=1)\n",
    "avg_CAs = np.nanmean(dice[:, 9:], axis=1)\n",
    "print(f'\\tgroup GCs:\\t{np.nanmean(avg_GCs):0.4f} ± {np.nanstd(avg_GCs):0.4f}')\n",
    "print(f'\\tgroup GVs:\\t{np.nanmean(avg_GVs):0.4f} ± {np.nanstd(avg_GVs):0.4f}')\n",
    "print(f'\\tgroup CAs:\\t{np.nanmean(avg_CAs):0.4f} ± {np.nanstd(avg_CAs):0.4f}')\n",
    "import numpy as np\n",
    "dice = np.nanmean(dice, axis=1)\n",
    "\n",
    "best = np.where(dice==np.nanmax(dice))\n",
    "worst = np.where(dice==np.nanmin(dice))\n",
    "\n",
    "cout(f'\\nBest: {best[0]} -> {dice[best][0]:0.4f}')\n",
    "cout(f'Worst: {worst[0]} -> {dice[worst][0]:0.4f}')\n",
    "\n",
    "\n",
    "_files = paths\n",
    "cout(f'\\nAverage DSC for each test volume:')\n",
    "for i in range(dice.shape[0]):\n",
    "    _file = os.path.split(_files[i]['image'])[-1]\n",
    "    cout(f'[{i:02d}]: {_file} -> {dice[i]:0.4f}')\n",
    "    # cout(f'[{i:02d}]: -> {dice[i]:0.4f}')\n",
    "    # cout(f'Test Patient {i:02d} -> {dice[i]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EXAMPLE_nnUNET/nnUNET_bestworst.txt', 'w') as f:\n",
    "    f.write(f'Best: {best[0][0]} -> {dice[best][0]:0.4f}\\n')\n",
    "    f.write(f'Worst: {worst[0][0]} -> {dice[worst][0]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout = print\n",
    "# cout = results_logger.info\n",
    "\n",
    "structures = ['RA','LA','RV','LV','AA','SVC','IVC','PA','PV','LMCA','LADA','RCA']\n",
    "cout(f'HD95 for ViewRay patients (n={len(testing_dataset)})')\n",
    "\n",
    "hd = manager.metric_fns['val_shd'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "# dice = manager.metric_fns['val_dice'].results.type(torch.float).squeeze(1).cpu()[:, 1:].numpy()\n",
    "sub_std = np.nanstd(hd, axis=0)\n",
    "\n",
    "p_hd = np.nanmean(hd, axis=1)\n",
    "# print(p_dice)\n",
    "cout(f'Total average HD95 without background = {np.nanmean(hd):0.4} ± {p_hd.std():0.4f}')\n",
    "# if save_dir: np.save(os.path.join(save_dir, 'DSC.metrics.npy'), dice)\n",
    "\n",
    "subs = np.nanmean(hd, axis=0)\n",
    "no_WH = subs[1:].mean()\n",
    "cout('Breakdown by substructure: (mean ± std)')\n",
    "[cout(f'\\tSub {structures[i]}: \\t{subs[i]:0.4f} ± {sub_std[i]:0.4f}') for i in range(len(subs))]\n",
    "\n",
    "print()\n",
    "\n",
    "# print(dice.shape)\n",
    "avg_GCs = np.nanmean(hd[:, :4], axis=1)\n",
    "avg_GVs = np.nanmean(hd[:, 4:9], axis=1)\n",
    "avg_CAs = np.nanmean(hd[:, 9:], axis=1)\n",
    "print(f'\\tgroup GCs:\\t{np.nanmean(avg_GCs):0.4f} ± {np.nanstd(avg_GCs):0.4f}')\n",
    "print(f'\\tgroup GVs:\\t{np.nanmean(avg_GVs):0.4f} ± {np.nanstd(avg_GVs):0.4f}')\n",
    "print(f'\\tgroup CAs:\\t{np.nanmean(avg_CAs):0.4f} ± {np.nanstd(avg_CAs):0.4f}')\n",
    "import numpy as np\n",
    "hd = np.nanmean(hd, axis=1)\n",
    "\n",
    "worst_hd = np.where(hd==np.nanmax(hd))\n",
    "best_hd = np.where(hd==np.nanmin(hd))\n",
    "\n",
    "cout(f'\\nBest: {best_hd[0]} -> {hd[best_hd][0]:0.4f}')\n",
    "cout(f'Worst: {worst_hd[0]} -> {hd[worst_hd][0]:0.4f}')\n",
    "\n",
    "# cout(f'\\nAverage DSC for each test volume:')\n",
    "# for i in range(dice.shape[0]):\n",
    "#     cout(f'Test Patient {i:02d} -> {dice[i]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics - DSC graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = manager.metric_fns['val_dice'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "\n",
    "\n",
    "structures = ['Total','RA','LA','RV','LV','AA','SVC','IVC','PA','PV','LMCA','LADA','RCA']\n",
    "averages = [np.nanmean(dice)] + list(np.nanmean(dice, axis=0))\n",
    "stds = [np.nanstd(np.nanmean(dice, axis=1))] + list(np.nanstd(dice, axis=0))\n",
    "\n",
    "pd.DataFrame({'Structures': structures, 'AVG': averages, 'STD': stds})\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "fig, (ax, tab) = plt.subplots(dpi=150, figsize=(8, 4), ncols=2, width_ratios=[5,1])\n",
    "\n",
    "\n",
    "\n",
    "x = [i for i in range(13)]\n",
    "dice = manager.metric_fns['val_dice'].results.type(torch.float).squeeze(1).cpu().numpy()\n",
    "p_dice = np.nanmean(dice, axis=1)\n",
    "\n",
    "box_args = {\n",
    "    'showmeans': True,\n",
    "    'widths': 0.5,\n",
    "    'showfliers': True,\n",
    "    'patch_artist':True,\n",
    "    'meanprops': {\n",
    "        'marker': '.',\n",
    "        'markerfacecolor': 'w',\n",
    "        'markeredgecolor': 'k',\n",
    "        'markersize': 10\n",
    "        },\n",
    "    'medianprops': {\n",
    "        'color': 'k'\n",
    "        },\n",
    "    'flierprops': {\n",
    "        'marker': '.',\n",
    "        'markerfacecolor': 'k',\n",
    "        }\n",
    "    }\n",
    "box_bkg = ax.boxplot(x=p_dice, positions=x[:1], **box_args)\n",
    "box_GC = ax.boxplot(x=dice[:, 0:4], positions=x[1:5], **box_args)\n",
    "box_GV = ax.boxplot(x=dice[:, 4:9], positions=x[5:10], **box_args)\n",
    "box_CA = ax.boxplot(x=dice[:, 9:], positions=x[10:], **box_args)\n",
    "\n",
    "for box, color in zip([box_bkg, box_GC, box_GV, box_CA], ['k', 'firebrick', 'royalblue', 'forestgreen']):\n",
    "    for b in box['boxes']:\n",
    "        b.set(edgecolor='k', linewidth=1)\n",
    "        b.set(facecolor=color)\n",
    "\n",
    "ax.plot([], [], marker='.', markerfacecolor='w', markeredgecolor='k', markersize=8, linestyle='none', label='Average')\n",
    "ax.plot([], [], linestyle='-', linewidth=1, color='k', label='Median')\n",
    "\n",
    "\n",
    "ax.legend(fontsize=10, ncols=1, loc = 'upper right', frameon=False, handlelength=1)\n",
    "\n",
    "ax.plot([0.5, 0.5], [-0.5, 1], c='k', ls='--')\n",
    "ax.plot([4.5, 4.5], [-0.5, 1], c='k', ls='--')\n",
    "ax.plot([9.5, 9.5], [-0.5, 1], c='k', ls='--')\n",
    "\n",
    "ax.set_xlim([-0.5, 12.5])\n",
    "ax.set_ylim([0, 1])\n",
    "# ax.set_ylim([0, 1.2])\n",
    "\n",
    "structures = ['Total','RA','LA','RV','LV','AA','SVC','IVC','PA','PV','LMCA','LADA','RCA']\n",
    "ax.set_xticklabels(structures, rotation=45)\n",
    "ax.set_title(f'Dice Similarity Coefficient (DSC' + r'$\\uparrow$' + f', n={dice.shape[0]}) [nnUNETwSD, no Fractions]', weight='bold')\n",
    "# fig.text(0.5, 0.95, 'Dice Similarity Coefficient (DSC, n=12)', ha='center', va='center', weight='bold', fontsize=12)\n",
    "ax.set_ylabel('DSC (AU)')\n",
    "# ax.set_ylabel('Worse ' + r'$\\leftarrow$' + ' DSC (AU) ' + r'$\\rightarrow$' + ' Better')\n",
    "\n",
    "text_args = {\n",
    "    'ha': 'center',\n",
    "    'va': 'center',\n",
    "    'fontsize': 12,\n",
    "    'weight': 'normal'\n",
    "}\n",
    "# ax.text(2.5, 0.075, 'Great\\nChambers', color='firebrick', **text_args)\n",
    "# ax.text(7, 0.075, 'Great\\nVeins', color='royalblue', **text_args)\n",
    "# ax.text(11, 0.075, 'Coronary\\nArteries', color='forestgreen', **text_args)\n",
    "ax.text(2.5, -0.25, 'Great\\nChambers', color='firebrick', **text_args)\n",
    "ax.text(7, -0.25, 'Great\\nVeins', color='royalblue', **text_args)\n",
    "ax.text(11, -0.25, 'Coronary\\nArteries', color='forestgreen', **text_args)\n",
    "\n",
    "\n",
    "tab.axis('off')\n",
    "tab.set_yticks([])\n",
    "tab.set_xticks([])\n",
    "\n",
    "tab.set_ylim([-2.5, 11.5])\n",
    "tab.set_xlim([-0.5, 3])\n",
    "structures = ['Name'] + structures\n",
    "averages = ['  AVG '] + averages\n",
    "stds = [' STD '] + stds\n",
    "\n",
    "k = 'k'\n",
    "r = 'firebrick'\n",
    "b = 'royalblue'\n",
    "g = 'forestgreen'\n",
    "colors = [k, k, r, r, r, r, b, b, b, b, b, g, g, g]\n",
    "for i, (n, a, s, c) in enumerate(zip(structures, averages, stds, colors)):\n",
    "    if i != 0:\n",
    "        tab.text(0, 11-i, f'{n}:', ha='left', va='center', fontsize=10, color=c)\n",
    "        tab.text(1.75, 11-i, f'{a:0.3f} ± {s:0.3f}', ha='left', va='center')\n",
    "    else:\n",
    "        # tab.text(0, 11-i, f'{n}', ha='left', va='center', fontsize=10)\n",
    "        tab.text(0.5, 11-i, 'AVG ± STD (AU)', ha='left', va='center')\n",
    "        # tab.text(1.75, 11-i, f'{a}   {s}', ha='left', va='center')\n",
    "plt.subplots_adjust(wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = manager.metric_fns['val_shd'].results.type(torch.float).squeeze(1).cpu().numpy() # No background is calcualted\n",
    "\n",
    "\n",
    "structures = ['Total','RA','LA','RV','LV','AA','SVC','IVC','PA','PV','LMCA','LADA','RCA']\n",
    "averages = [np.nanmean(dice)] + list(np.nanmean(dice, axis=0))\n",
    "stds = [np.nanstd(np.nanmean(dice, axis=1))] + list(np.nanstd(dice, axis=0))\n",
    "\n",
    "pd.DataFrame({'Structures': structures, 'AVG': averages, 'STD': stds})\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "fig, (ax, tab) = plt.subplots(dpi=150, figsize=(8, 4), ncols=2, width_ratios=[5,1])\n",
    "\n",
    "\n",
    "\n",
    "x = [i for i in range(13)]\n",
    "dice = manager.metric_fns['val_shd'].results.type(torch.float).squeeze(1).cpu().numpy()\n",
    "p_dice = np.nanmean(dice, axis=1)\n",
    "\n",
    "box_args = {\n",
    "    'showmeans': True,\n",
    "    'widths': 0.5,\n",
    "    'showfliers': True,\n",
    "    'patch_artist':True,\n",
    "    'meanprops': {\n",
    "        'marker': '.',\n",
    "        'markerfacecolor': 'w',\n",
    "        'markeredgecolor': 'k',\n",
    "        'markersize': 10\n",
    "        },\n",
    "    'medianprops': {\n",
    "        'color': 'k'\n",
    "        },\n",
    "    'flierprops': {\n",
    "        'marker': '.',\n",
    "        'markerfacecolor': 'k',\n",
    "        }\n",
    "    }\n",
    "box_bkg = ax.boxplot(x=p_dice, positions=x[:1], **box_args)\n",
    "box_GC = ax.boxplot(x=dice[:, 0:4], positions=x[1:5], **box_args)\n",
    "box_GV = ax.boxplot(x=dice[:, 4:9], positions=x[5:10], **box_args)\n",
    "\n",
    "CA_boxes = []\n",
    "for i in range(9, 12):\n",
    "    ca = dice[:, i][~np.isnan(dice[:, i])]\n",
    "    CA_boxes.append(ax.boxplot(x=ca, positions=[i+1], **box_args))\n",
    "\n",
    "# CAs = dice[:, 9:]#[~np.isnan(dice[:,9:])]\n",
    "# box_CA = ax.boxplot(x=CAs, positions=x[10:], **box_args)\n",
    "\n",
    "for box, color in zip([box_bkg, box_GC, box_GV], ['k', 'firebrick', 'royalblue']):\n",
    "    for b in box['boxes']:\n",
    "        b.set(edgecolor='k', linewidth=1)\n",
    "        b.set(facecolor=color)\n",
    "\n",
    "box_color = 'forestgreen'\n",
    "for box in CA_boxes:\n",
    "    for b in box['boxes']:\n",
    "        b.set(edgecolor='k', linewidth=1)\n",
    "        b.set(facecolor=box_color)\n",
    "\n",
    "ax.plot([], [], marker='.', markerfacecolor='w', markeredgecolor='k', markersize=8, linestyle='none', label='Average')\n",
    "ax.plot([], [], linestyle='-', linewidth=1, color='k', label='Median')\n",
    "\n",
    "\n",
    "ax.legend(fontsize=10, ncols=1, loc = 'upper right', frameon=False, handlelength=1)\n",
    "\n",
    "_max_dice = np.nanmax(dice)\n",
    "ax.plot([0.5, 0.5], [-1*_max_dice, 1.5*_max_dice], c='k', ls='--')\n",
    "ax.plot([4.5, 4.5], [-1*_max_dice, 1.5*_max_dice], c='k', ls='--')\n",
    "ax.plot([9.5, 9.5], [-1*_max_dice, 1.5*_max_dice], c='k', ls='--')\n",
    "\n",
    "ax.set_xlim([-0.5, 12.5])\n",
    "ax.set_ylim([0, 1.25*_max_dice])\n",
    "# ax.set_ylim([0, 1.2])\n",
    "# ax.set_yticks([5*i for i in range(7)])\n",
    "print(int(_max_dice // 10))\n",
    "ax.set_yticks([10*i for i in range(int(_max_dice // 10)+1)])\n",
    "structures = ['Total','RA','LA','RV','LV','AA','SVC','IVC','PA','PV','LMCA','LADA','RCA']\n",
    "ax.set_xticklabels(structures, rotation=45)\n",
    "ax.set_title('95% Hausdorf Distance (HD95' + r'$\\downarrow$' + f', n={dice.shape[0]}) [nnUNETwSD, no Fractions]', weight='bold')\n",
    "# fig.text(0.5, 0.95, 'Dice Similarity Coefficient (DSC, n=12)', ha='center', va='center', weight='bold', fontsize=12)\n",
    "ax.set_ylabel('HD95 (mm)')\n",
    "# ax.set_ylabel('Worse ' + r'$\\leftarrow$' + ' DSC (AU) ' + r'$\\rightarrow$' + ' Better')\n",
    "\n",
    "text_args = {\n",
    "    'ha': 'center',\n",
    "    'va': 'bottom',\n",
    "    'fontsize': 12,\n",
    "    'weight': 'normal'\n",
    "}\n",
    "# ax.text(2.5, -0.1*_max_dice, 'Great\\nChambers', color='firebrick', **text_args)\n",
    "# ax.text(7, -0.1*_max_dice, 'Great\\nVeins', color='royalblue', **text_args)\n",
    "# ax.text(11, -0.1*_max_dice, 'Coronary\\nArteries', color='forestgreen', **text_args)\n",
    "ax.text(2.5, -0.3*(1.25*_max_dice), 'Great\\nChambers', color='firebrick', **text_args)\n",
    "ax.text(7, -0.3*(1.25*_max_dice), 'Great\\nVeins', color='royalblue', **text_args)\n",
    "ax.text(11, -0.3*(1.25*_max_dice), 'Coronary\\nArteries', color='forestgreen', **text_args)\n",
    "\n",
    "\n",
    "\n",
    "tab.axis('off')\n",
    "tab.set_yticks([])\n",
    "tab.set_xticks([])\n",
    "\n",
    "tab.set_ylim([-2.5, 11.5])\n",
    "tab.set_xlim([-0.5, 3])\n",
    "structures = ['Name'] + structures\n",
    "averages = ['  AVG '] + averages\n",
    "stds = [' STD '] + stds\n",
    "\n",
    "k = 'k'\n",
    "r = 'firebrick'\n",
    "b = 'royalblue'\n",
    "g = 'forestgreen'\n",
    "colors = [k, k, r, r, r, r, b, b, b, b, b, g, g, g]\n",
    "for i, (n, a, s, c) in enumerate(zip(structures, averages, stds, colors)):\n",
    "    if i != 0:\n",
    "        tab.text(0, 11-i, f'{n}:', ha='left', va='center', fontsize=10, color=c)\n",
    "        tab.text(1.75, 11-i, f'{a:0.3f} ± {s:0.3f}', ha='left', va='center')\n",
    "    else:\n",
    "        # tab.text(0, 11-i, f'{n}', ha='left', va='center', fontsize=10)\n",
    "        tab.text(0.5, 11-i, f'AVG ± STD (mm)', ha='left', va='center')\n",
    "        # tab.text(1.75, 11-i, f'{a}   {s}', ha='left', va='center')\n",
    "plt.subplots_adjust(wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ViewRay_diceresults.npy', dice, allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of the testing images / labels\n",
    "imgs, labs = [], []\n",
    "for _set in testing_dataset:\n",
    "    img, lab = _set['image'][0, 0], _set['label'][0, 0]\n",
    "    imgs.append(img)\n",
    "    labs.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of the testing images / labels\n",
    "imgs, labs = [], []\n",
    "for _set in testing_dataset:\n",
    "    img, lab = _set['image'][0, 0], _set['label'][0, 0]\n",
    "    imgs.append(img)\n",
    "    labs.append(lab)\n",
    "    \n",
    "preds = [pred[0] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.stack(preds, dim=0)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "#  Plotting the BEST masks\n",
    "# best_preds = os.path.join(save_dir, 'Prediction.Best')\n",
    "# os.makedirs(best_preds, exist_ok=True)\n",
    "\n",
    "best_i = best[0][0]\n",
    "# Getting the best img / label / mask\n",
    "img = imgs[best_i]\n",
    "lab = labs[best_i]\n",
    "\n",
    "os.makedirs('EXAMPLE_nnUNET', exist_ok=True)\n",
    "nib.save(img=nib.nifti1.Nifti1Image(img.numpy(), affine=np.eye(4)), filename='EXAMPLE_nnUNET/BestIMG.nii.gz')\n",
    "nib.save(img=nib.nifti1.Nifti1Image(lab.numpy(), affine=np.eye(4)), filename='EXAMPLE_nnUNET/BestPRD.nii.gz')\n",
    "\n",
    "print(img.dtype)\n",
    "\n",
    "pred = predictions[best_i].cpu().detach()\n",
    "pred = torch.argmax(pred, dim=1)[0].numpy()\n",
    "pred = np.float32(pred)\n",
    "print(pred.shape)\n",
    "nib.save(img=nib.nifti1.Nifti1Image(pred, affine=np.eye(4)), filename='EXAMPLE_nnUNET/BestLAB.nii.gz')\n",
    "\n",
    "\n",
    "pred = np.ma.masked_where(pred==0, pred)\n",
    "lab = np.ma.masked_where(lab==0, lab)\n",
    "\n",
    "for i in range(pred.shape[-1]):\n",
    "    if np.nansum(pred[..., i]):\n",
    "        fig, ax = plt.subplots(ncols=3, figsize=(18,6.5))\n",
    "        ax[0].imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title(f'Image, slice {i}', fontsize=24)\n",
    "\n",
    "        ax[1].imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "        ax[1].imshow(pred[..., i], cmap='Reds', vmin=0, vmax=pred.max(), interpolation='none')\n",
    "        ax[1].axis('off')\n",
    "        ax[1].set_title(f'Prediction, slice {i}', fontsize=24)\n",
    "\n",
    "        ax[2].imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "        ax[2].imshow(lab[..., i], cmap='Reds', vmin=0, vmax=pred.max(), interpolation='none')\n",
    "        ax[2].axis('off')\n",
    "        ax[2].set_title(f'GT, slice {i}', fontsize=24)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        # plt.savefig(os.path.join(best_preds, f'slice.{i:04d}.png'), dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "# if save_dir:\n",
    "#     frames = [Image.open(file) for file in sorted(glob.glob(os.path.join(best_preds, '*.png')))]\n",
    "#     frames[0].save(os.path.join(save_dir, 'Prediction.Best.gif'), format=\"GIF\", append_images=frames, save_all=True, duration=300, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the WORST masks\n",
    "# worst_preds = os.path.join(save_dir, 'Prediction.Worst')\n",
    "# os.makedirs(worst_preds, exist_ok=True)\n",
    "\n",
    "worst_ = worst[0][0]\n",
    "# Getting the best img / label / mask\n",
    "img = imgs[worst_]\n",
    "lab = labs[worst_]\n",
    "\n",
    "os.makedirs('EXAMPLE_nnUNET', exist_ok=True)\n",
    "nib.save(img=nib.nifti1.Nifti1Image(img.numpy(), affine=np.eye(4)), filename='EXAMPLE_nnUNET/worstIMG.nii.gz')\n",
    "nib.save(img=nib.nifti1.Nifti1Image(lab.numpy(), affine=np.eye(4)), filename='EXAMPLE_nnUNET/worstPRD.nii.gz')\n",
    "\n",
    "pred = predictions[worst_].cpu().detach()\n",
    "pred = torch.argmax(pred, dim=1)[0].numpy()\n",
    "pred = np.float32(pred)\n",
    "nib.save(img=nib.nifti1.Nifti1Image(pred, affine=np.eye(4)), filename='EXAMPLE_nnUNET/worstLAB.nii.gz')\n",
    "\n",
    "pred = np.ma.masked_where(pred==0, pred)\n",
    "lab = np.ma.masked_where(lab==0, lab)\n",
    "\n",
    "for i in range(pred.shape[-1]):\n",
    "    if np.nansum(pred[..., i]):\n",
    "        fig, ax = plt.subplots(ncols=3, figsize=(18,6.5))\n",
    "        ax[0].imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title(f'Image, slice {i}', fontsize=24)\n",
    "\n",
    "        ax[1].imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "        ax[1].imshow(pred[..., i], cmap='Reds', vmin=0, vmax=pred.max(), interpolation='none')\n",
    "        ax[1].axis('off')\n",
    "        ax[1].set_title(f'Prediction, slice {i}', fontsize=24)\n",
    "\n",
    "        ax[2].imshow(img[..., i], cmap='gray', vmin=img.min(), vmax=img.max())\n",
    "        ax[2].imshow(lab[..., i], cmap='Reds', vmin=0, vmax=pred.max(), interpolation='none')\n",
    "        ax[2].axis('off')\n",
    "        ax[2].set_title(f'GT, slice {i}', fontsize=24)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        # plt.savefig(os.path.join(worst_preds, f'slice.{i:04d}.png'), dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "# if save_dir:\n",
    "#     frames = [Image.open(file) for file in sorted(glob.glob(os.path.join(worst_preds, '*.png')))]\n",
    "#     frames[0].save(os.path.join(save_dir, 'Prediction.Worst.gif'), format=\"GIF\", append_images=frames, save_all=True, duration=300, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mv5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f40f9922b7e55386a94bbb5a8e88ccb2722010d4a75fee8a7e0ee19a818aef8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
